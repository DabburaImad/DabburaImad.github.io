{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a8df91-0b76-4abe-a256-ca7df2fd17dd",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Airflow Part 7 - Triggering Workflows\"\n",
    "date: \"2022-09-26\"\n",
    "image: feature.png\n",
    "categories: [\"Data Engineering\", \"MLOps\"]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48243cb5-f66b-4d0c-9dc3-fb567d6cc643",
   "metadata": {},
   "source": [
    "![](feature.png){fig-align=\"center\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3638d166-331d-40b0-a727-94a68dc4cde5",
   "metadata": {},
   "source": [
    "- It is meant to exchange messages between tasks, which is some form of shared state\n",
    "- We can use dag instance to push/pull data between tasks:\n",
    "    - `conext[\"dag_instance\"].xcom_push(key=\"data_name\", value=\"value\")` to push data to metastore. It also store the `dag_id`, `task_id`, & `execution_date`.\n",
    "    - `conext[\"dag_instance\"].xcom_pull(key=\"data_name\")` which pull the shared data. We can also specify `dag_id` and `execution_date`.\n",
    "    - We can also access push/pull methods in templates using `task_instance.xcom_push()` or `task_instance.xcom_pull()`\n",
    "    - We can view the shared data on the UI by going to Admin -> XComs\n",
    "\n",
    "- **Limitations**:\n",
    "    - XComs data will be pickled and stored in the database -> The objects have to be serializable\n",
    "    - Size limitations:\n",
    "        - SQLite—Stored as BLOB type, 2GB limit\n",
    "        - PostgreSQL—Stored as BYTEA type, 1 GB limit \n",
    "        - MySQL—Stored as BLOB type, 64 KB limit\n",
    "    - It create hidden dependency between tasks because now the task the pushes the shared state has to push the data before the task that pulls the data. Airflow won't manage/respect this dependency the developer has to document this and make sure this is not an issue based on the tasks' order\n",
    "- Due to its limitations in terms of size, we can create custom backends for XComs by defining a class that inherits from `BaseXCom` and implements two static methods. Airflow will use this class. It can be added to `xcom_backend` parameter in the Airflow configWe can use cheap/large storage services on the cloud such as Amazon S3, Azure Blob Storage, or Google GCS.\n",
    "\n",
    "```python\n",
    "from typing import Any\n",
    "from airflow.models.xcom import BaseXCom\n",
    "\n",
    "class CustomXComBackend(BaseXCom):\n",
    "    \n",
    "    @staticmethod\n",
    "    def serialize(value: Any):\n",
    "        ...\n",
    "    \n",
    "    @staticmethod\n",
    "    def deserialize(result):\n",
    "        ...\n",
    "```\n",
    "- If most of tasks are PythonOperators, we can use `Taskflow` API that takes care of passing state between tasks and avoid the boilerplate code that we have to write with regular API. We need to just decorate the function that we use in the PythonOperator with `@task` and Airflow will take care of the rest by passed XCom data between tasks. Example:\n",
    "\n",
    "<img src=\"images/taskflow-example.png\">\n",
    "\n",
    "```python\n",
    "from airflow.decorators import task\n",
    "\n",
    "\n",
    "with DAG(...) as dag:\n",
    "    start = DummyOperator(task_id=\"start\")\n",
    "    start >> fetch_sales\n",
    "    start >> fetch_weather\n",
    "    fetch_sales >> clean_sales\n",
    "    fetch_weather >> clean_weather\n",
    "    [clean_sales, clean_weather] >> join_datasets\n",
    "    \n",
    "    @task\n",
    "    def train_model():\n",
    "        model_id = str(uuid.uuid4())\n",
    "        # Airflow will figure out that the return value is XCom\n",
    "        # and would take care of pushing it\n",
    "        return model_id\n",
    "\n",
    "    @task\n",
    "    def deploy_model(model_id: str):\n",
    "        # Airflow would realize that this task uses XCom so it passes\n",
    "        # it from XCom\n",
    "        print(f\"Deploying model {model_id}\")\n",
    "\n",
    "model_id = train_model()\n",
    "deploy_model(model_id)\n",
    "\n",
    "# Now train_model and deploy_model will be new tasks\n",
    "# with explicit dependeny. \n",
    "# The task type is PythonDecoratedOperator\n",
    "join_datasets >> model_id\n",
    "```\n",
    "- Any data passed between Taskflow-style tasks will be stored as XComs and subject to the same limitations of XCom\n",
    "- The main limitation of Taskflow API is that it is still only for PythonOperators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794fa8c7-b38b-4c2b-9b8f-3269465ebe9f",
   "metadata": {},
   "source": [
    "- Workflows are most commonly triggered based on schedule intervals provided using `start_date`, `end_date` , `schedule_interval`. Airflow would calculate when the next schedule would be and start the first task(s) to run at the next data/time.\n",
    "- However, sometimes we want the workflow to run based on the occurance of external events such as a file is available in specific location OR code is changed on git repo etc.\n",
    "- One way to execute workflows based on the occurance of external exents is using Airflow's **sensors**. Sensor is a subclass of operators that checks if certain condition is true. If true, execute the step (workflow). If false, wait for a given period (default 60 seconds) and tries again. It keeps doing so for *timeout* period. This is a form of **Poking**, which is checking for the existence of file in the case of FileSensor.\n",
    "\n",
    "```Python\n",
    "from airflow.sensors.filesystem import FileSensor\n",
    "wait_for_file_1 = FileSensor(\n",
    "    task_id=\"wait_for_file_1\", filepath=\"/data/file_1.csv\"\n",
    "    )\n",
    "```\n",
    "- We can also use **globbing** with FileSensors by using wildcards to check for the existence of file(s)\n",
    "- We can also use PythonSensor which checks for certain condition and must return a Boolean. It is more flexible and easier to read than using globbing within FileSensor. It is the same as PythonOperator in terms of taking a Python callable\n",
    "\n",
    "```Python\n",
    "from pathlib import Path\n",
    "from airflow.sensors.python import PythonSensor\n",
    "\n",
    "# Check whether there is any data for a given supermarker\n",
    "# and there is _SUCCESS path which indicates whether the \n",
    "# data for the given supermarket is all uploaded\n",
    "def _wait_for_supermarket(supermarket):\n",
    "    supermarket_path = Path(\"/data\") / supermarket\n",
    "    success_path = Path(\"/data\") / \"_SUCCESS\"\n",
    "    data_files = supermarketpath.glob(\"*.csv\")\n",
    "    return data_files and success_path.exists()\n",
    "\n",
    "wait_for_supermarket_1 = PythonSensor(\n",
    "    task_id=\"wait_for_supermarket_1\",\n",
    "    python_callable=_wait_for_supermarket,\n",
    "    op_kwargs={\"supermarket\": \"supermarket_1\"},\n",
    "    dag=dag\n",
    "    )\n",
    "```\n",
    "<img src=\"images/python-sensor.png\">\n",
    "\n",
    "- All sensors take a `timeout` arguments, which has default value of 7 days\n",
    "- There is also a limit on the number of tasks Airflow can run concurrently per DAG (default is 16). DAG takes `concurrency` argument that can change this number. There is also a limit on the number of tasks per global Airflow and the number DAG runs per DAG\n",
    "```Python\n",
    "wait_for_supermarket_1 = PythonSensor(\n",
    "    task_id=\"wait_for_supermarket_1\",\n",
    "    python_callable=_wait_for_supermarket,\n",
    "    op_kwargs={\"supermarket\": \"supermarket_1\"},\n",
    "    concurreny=20, # Default is 16\n",
    "    dag=dag\n",
    "    )\n",
    "```\n",
    "- There is snowball effect when sensors don't succeed. The occupy slots that DAG has (which is determined by the concurrency argument. From the above figure, if only task 1 succeeds and the rest keeps polling and the DAG is scheduled daily with default concurrency of 16 slots and default timeout of 7 days, this is what will happen (sensor deadlock):\n",
    "    - Day 1: Supermarket 1 succeeded; supermarkets 2, 3, and 4 are polling, occupying 3 tasks.\n",
    "    - Day 2: Supermarket 1 succeeded; supermarkets 2, 3, and 4 are polling, occupying 6 tasks.\n",
    "    - Day 3: Supermarket 1 succeeded; supermarkets 2, 3, and 4 are polling, occupying 9 tasks.\n",
    "    - Day 4: Supermarket 1 succeeded; supermarkets 2, 3, and 4 are polling, occupying 12 tasks.\n",
    "    - Day 5: Supermarket 1 succeeded; supermarkets 2, 3, and 4 are polling, occupying 15 tasks.\n",
    "    - Day 6: Supermarket 1 succeeded; supermarkets 2, 3, and 4 are polling, occupying 16 tasks; two new tasks cannot run, and any other task trying to run is blocked.\n",
    "\n",
    "<img src=\"images/python-sensor-deadlock.png\">\n",
    "\n",
    "- This also affect the global Airflow limit of maximum number of tasks that can run concurrently, which may lead to whole system get stalled. \n",
    "- For sensor task, it pokes to check the condition and block if it is false. So it would run for a little bit and wait for the most part. It keeps poking untel the timeout period is completed, which means it keeps occupying the slot until the condition becomes true or timeout is reached\n",
    "- `mode` argument which has two values: {`poking`, `reschedule`}. The default is poking. Reschedule can solve the sensor deadlock and snowball effect because it releases the slot the sensor task is occupying after the slot has finished poking. In other words, sensor task would poke, if condition if false, the system will reschedule it and take its slot and make it available to other tasks. It is the same concept as **process scheduling** that the OS does when a process does a blocking system call.\n",
    "\n",
    "```Python\n",
    "wait_for_supermarket_1 = PythonSensor(\n",
    "    task_id=\"wait_for_supermarket_1\",\n",
    "    python_callable=_wait_for_supermarket,\n",
    "    op_kwargs={\"supermarket\": \"supermarket_1\"},\n",
    "    mode=\"reschedule\",\n",
    "    dag=dag\n",
    "    )\n",
    "```\n",
    "- We can trigger another DAG to run from inside another DAG using `TriggerDagRunOperator`. This will cause another DAG to run once the trigger_operator runs which is useful if we want to split DAGs and make some DAGs available to other DAGs instead of repearing functionality. See below for both approaches:\n",
    "<img src=\"images/complicated-dag-logic.png\">\n",
    "<img src=\"images/triggered-dag.png\">\n",
    "\n",
    "```Python\n",
    "from pathlib import Path\n",
    "\n",
    "import airflow.utils.dates\n",
    "from airflow import DAG\n",
    "from airflow.operators.dummy import DummyOperator\n",
    "from airflow.operators.trigger_dagrun import TriggerDagRunOperator\n",
    "from airflow.sensors.python import PythonSensor\n",
    "\n",
    "dag1 = DAG(\n",
    "    dag_id=\"ingest_supermarket_data\",\n",
    "    start_date=airflow.utils.dates.days_ago(3),\n",
    "    schedule_interval=\"0 16 * * *\",\n",
    ")\n",
    "dag2 = DAG(\n",
    "    dag_id=\"create_metrics\",\n",
    "    start_date=airflow.utils.dates.days_ago(3),\n",
    "    schedule_interval=None, # Since it will be triggered\n",
    ")\n",
    "\n",
    "\n",
    "def _wait_for_supermarket(supermarket_id_):\n",
    "    supermarket_path = Path(\"/data/\" + supermarket_id_)\n",
    "    data_files = supermarket_path.glob(\"data-*.csv\")\n",
    "    success_file = supermarket_path / \"_SUCCESS\"\n",
    "    return data_files and success_file.exists()\n",
    "\n",
    "\n",
    "for supermarket_id in range(1, 5):\n",
    "    wait = PythonSensor(\n",
    "        task_id=f\"wait_for_supermarket_{supermarket_id}\",\n",
    "        python_callable=_wait_for_supermarket,\n",
    "        op_kwargs={\"supermarket_id_\": f\"supermarket{supermarket_id}\"},\n",
    "        dag=dag1,\n",
    "    )\n",
    "    copy = DummyOperator(task_id=f\"copy_to_raw_supermarket_{supermarket_id}\", dag=dag1)\n",
    "    process = DummyOperator(task_id=f\"process_supermarket_{supermarket_id}\", dag=dag1)\n",
    "    trigger_create_metrics_dag = TriggerDagRunOperator(\n",
    "        task_id=f\"trigger_create_metrics_dag_supermarket_{supermarket_id}\",\n",
    "        trigger_dag_id=\"create_metrics\", # Has to be the same dag_id as dag2\n",
    "        dag=dag1,\n",
    "    )\n",
    "    wait >> copy >> process >> trigger_create_metrics_dag\n",
    "\n",
    "compute_differences = DummyOperator(task_id=\"compute_differences\", dag=dag2)\n",
    "update_dashboard = DummyOperator(task_id=\"update_dashboard\", dag=dag2)\n",
    "notify_new_data = DummyOperator(task_id=\"notify_new_data\", dag=dag2)\n",
    "compute_differences >> update_dashboard\n",
    "\n",
    "```\n",
    "- Each DAG run has a run_id that starts with one of the following:\n",
    "    - `scheduled__` to indicate the DAG run started because of its schedule\n",
    "    - `backfill__` to indicate the DAG run started by a backfill job\n",
    "    - `manual__` to indicate the DAG run started by a manual action (e.g., pressing the Trigger Dag button, or triggered by a TriggerDagRunOperator)\n",
    "- From the UI, scheduled DAGs have their task instance in black border while Triggered DAGs don't\n",
    "- Clearing a task in a DAG will clear the task and all its downstream tasks and trigger a run (backfill)\n",
    "    - It only clears tasks within the same DAG, NOT downstream tasks in another DAG of TriggerDagRunOperator\n",
    "- If the triggered DAG has dependency on multiple triggering DAGs to be completed before it can run, then we can use `ExternalTaskSensor` that checks whether the task has been completed successfully (sensor poking the state of tasks in another DAGs). Each `ExternalTaskSensor` checks for only 1 task by querying the metastore database\n",
    "    - By default, it uses the same execution_date as itself\n",
    "    - If the task runs on different schedule, we then need to provide timedelta object to `execution_delta` argument to get what would be the execution_date of the task it tries to sense\n",
    "\n",
    "```Python\n",
    "import datetime\n",
    "\n",
    "import airflow.utils.dates\n",
    "from airflow import DAG\n",
    "from airflow.operators.dummy import DummyOperator\n",
    "from airflow.sensors.external_task import ExternalTaskSensor\n",
    "\n",
    "dag1 = DAG(\n",
    "    dag_id=\"ingest_supermarket_data\",\n",
    "    start_date=airflow.utils.dates.days_ago(3),\n",
    "    schedule_interval=\"0 16 * * *\",\n",
    ")\n",
    "dag2 = DAG(\n",
    "    dag_id=\"create_metrics\",\n",
    "    start_date=airflow.utils.dates.days_ago(3),\n",
    "    schedule_interval=\"0 18 * * *\",\n",
    ")\n",
    "\n",
    "DummyOperator(task_id=\"copy_to_raw\", dag=dag1) >> DummyOperator(\n",
    "    task_id=\"process_supermarket\", dag=dag1\n",
    ")\n",
    "\n",
    "wait = ExternalTaskSensor(\n",
    "    task_id=\"wait_for_process_supermarket\",\n",
    "    external_dag_id=\"figure_6_20_dag_1\",\n",
    "    external_task_id=\"process_supermarket\",\n",
    "    # positive # will be subtracted from the execution_date of task sensor\n",
    "    # to get the execution_date of the task it is trying to sense\n",
    "    execution_delta=datetime.timedelta(hours=6),  \n",
    "    dag=dag2,\n",
    ")\n",
    "report = DummyOperator(task_id=\"report\", dag=dag2)\n",
    "wait >> report\n",
    "```\n",
    "- We can also trigger DAGs from CLI which will have execution_date of the current data and time\n",
    "    - `airflow dags trigger dag1`\n",
    "    - With configuration; which will be available in the context of each task using context[\"dag_run\"].conf:\n",
    "        - `airflow dags trigger -c '{\"supermarket_id\": 1}' dag1`\n",
    "        - `airflow dags trigger --conf '{\"supermarket_id\": 1}' dag1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11931e28-7ba8-4233-87e0-8558e01614ed",
   "metadata": {},
   "source": [
    "- Stick to coding style conventions by using tools like flake8, pylint, black\n",
    "- There are two ways to define DAGs. Stick to one of them:\n",
    "    1. With context manager: \n",
    "```Python\n",
    "   with DAG(...) as dag:\n",
    "        task1 = PythonOperator(...)\n",
    "        task2 = PythonOperator(...)\n",
    "```\n",
    "    2. Traditional:\n",
    "```Python\n",
    "   dag = DAG(...)\n",
    "   task1 = PythonOperator(..., dag=dag)\n",
    "   task2 = PythonOperator(..., dag=dag)\n",
    "```\n",
    "- There are also multiple ways to define dependencies. Stick to one of them:\n",
    "```Python\n",
    "    task1 >> task2\n",
    "    task1 << task2\n",
    "    [task1] >> task2\n",
    "    task1.set_downstream(task2)\n",
    "    task2.set_upstream(task1)\n",
    "```\n",
    "- When loading config files, make sure to understand where the loading happens:\n",
    "    - At the top level on the scheduler\n",
    "    - At the DAG level when it is parsed\n",
    "    - Or when the DAG is executing -> in the worker\n",
    "- Avoid doing any computation in DAG definition:\n",
    "    - At the top level, it will be computed every time the DAG is loaded\n",
    "    - In the DAG definition, it will be executed every time the DAG is parsed by the scheduler\n",
    "    - In the task, it will be computed when the task is executed on the worker machine\n",
    "- Fetch credentials within the task, so they are only fetched once the task is executed\n",
    "- Use factory methods to generate DAGs or set of tasks that are almost typical with few minor changes. Example:\n",
    "\n",
    "```Python\n",
    "def generate_tasks(dataset_name, raw_dir, processed_dir, preprocess_script, output_dir, dag):\n",
    "    raw_path = os.path.join(raw_dir, dataset_name, \"{ds_nodash}.json\") \n",
    "    processed_path = os.path.join(\n",
    "    processed_dir, dataset_name, \"{ds_nodash}.json\" )\n",
    "    output_path = os.path.join(output_dir, dataset_name, \"{ds_nodash}.json\")\n",
    "    fetch_task = BashOperator(\n",
    "        task_id=f\"fetch_{dataset_name}\",\n",
    "        bash_command=f\"echo 'curl http://example.com/{dataset_name}.json{raw_path}.json'\", dag=dag,\n",
    "        )\n",
    "    preprocess_task = BashOperator(\n",
    "        task_id=f\"preprocess_{dataset_name}\",\n",
    "        bash_command=f\"echo '{preprocess_script} {raw_path} {processed_path}'\", dag=dag,\n",
    "    )\n",
    "    export_task = BashOperator(\n",
    "        task_id=f\"export_{dataset_name}\",\n",
    "        bash_command=f\"echo 'cp {processed_path} {output_path}'\", dag=dag,\n",
    "       )\n",
    "        fetch_task >> preprocess_task >> export_task\n",
    "    return fetch_task, export_task\n",
    "\n",
    "with DAG(\n",
    "    dag_id=\"01_task_factory\",\n",
    "    start_date=airflow.utils.dates.days_ago(5),\n",
    "    schedule_interval=\"@daily\",\n",
    ") as dag:\n",
    "    for dataset in [\"sales\", \"customers\"]:\n",
    "        generate_tasks(\n",
    "            dataset_name=dataset,\n",
    "            raw_dir=\"/data/raw\", \n",
    "            processed_dir=\"/data/processed\", \n",
    "            output_dir=\"/data/output\",\n",
    "            preprocess_script=f\"preprocess_{dataset}.py\", dag=dag\n",
    "        )\n",
    "```\n",
    "- We can use `TaskGroup` to group related tasks into groups that will help us navigating the DAG in the UI. This is very helpful when DAGs become very complicated\n",
    "- Create new DAGs for big changes such as renaming/removing tasks or changing the schedule_date/interval so we can keep the historical info about old DAGs and not confuse the scheduler. Scheduler database has instances of the runs of each DAG\n",
    "- Make sure that tasks are idempotenet -> Regardless when they run, If given the same input the should produce the same output. Therefore, be careful when writing data. We may want to overwrite or upsert to avoid appending the same data\n",
    "    - Also, tasks should not have side effects\n",
    "- Avoid writing intermediate results on local filesystem because each task runs independently (and mostly on different machines) -> Use cloud shared storage such as Amazon's S3 bucket where all workers can access it\n",
    "- We can use SLAs on each DAG/task where Airflow will notify if they don't finish within SLA. DAG takes `sla` argument"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
